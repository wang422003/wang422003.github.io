---
---
@inproceedings{wang-2025-sgsi,
  abbr={ICML},
  selected={true},
  title =    {Guided Structural Inference: Leveraging Priors with Soft Gating Mechanisms},
  author =       {Wang, Aoran and Dai, Xinnan and Pang, Jun},
  booktitle =    {Proceedings of the 42rd International Conference on Machine Learning},
  year =   {2025},
  series =   {Proceedings of Machine Learning Research},
  publisher =    {PMLR},
  abstract =   {Existing methods for inferring latent relational structures struggle to integrate partial prior knowledge, such as known edges, node-degree constraints, and global sparsity, without destabilizing training or conflicting with probabilistic assumptions. We propose Soft-Gated Structural Inference (SGSI), a VAE framework that seamlessly incorporates domain constraints via (1) soft gating with learnable edge masks to preserve gradients, (2) cloning-clamping of deterministic edges to avoid distributional conflicts, and (3) adaptive regularization to balance data-driven learning with domain constraints. By excluding known edges from stochastic inference, SGSI reallocates capacity to uncertain interactions, optimizing the information bottleneck trade-off. Experiments on 16 datasets show SGSI improves edge recovery by up to 9% AUROC over baselines, scales to larger graphs (94.2% AUROC), and maintains stable training. SGSI bridges domain expertise with data-driven learning, enabling interpretable and robust structural discovery in dynamical systems.}
}


@misc{tong2025kolmogorovarnoldnetworkgeneregulatory,
  abbr={Arxiv},
  title={Kolmogorov-Arnold Network for Gene Regulatory Network Inference}, 
  author={Tsz Pan Tong and Aoran Wang and George Panagopoulos and Jun Pang},
  year={2025},
  eprint={2506.13740},
  archivePrefix={arXiv},
  primaryClass={cs.CE},
  url={https://arxiv.org/abs/2506.13740}, 
}

@inproceedings{wang2024sicsm,
  abbr={NeurIPS},
  selected={true},
  title={Structural Inference of Dynamical Systems with Conjoined State Space Models},
  author={Wang, Aoran and Pang, Jun},
  booktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems},
  year={2024},
  website={https://openreview.net/forum?id=xQWJBeK5rh},
  abstract={This paper introduces SICSM, a novel structural inference framework that integrates Selective State Space Models (selective SSMs) with Generative Flow Networks (GFNs) to handle the challenges posed by dynamical systems with irregularly sampled trajectories and partial observations. By utilizing the robust temporal modeling capabilities of selective SSMs, our approach learns input-dependent transition functions that adapt to non-uniform time intervals, thereby enhancing the accuracy of structural inference. By aggregating dynamics across diverse temporal dependencies and channeling them into the GFN, the SICSM adeptly approximates the posterior distribution of the system's structure. This process not only enables precise inference of complex interactions within partially observed systems but also ensures the seamless integration of prior knowledge, enhancing the model’s accuracy and robustness. Extensive evaluations on sixteen diverse datasets demonstrate that SICSM outperforms existing methods, particularly in scenarios characterized by irregular sampling and incomplete observations, which highlight its potential as a reliable tool for scientific discovery and system diagnostics in disciplines that demand precise modeling of complex interactions.}
}

@inproceedings{wang2024benchmarking,
  abbr={NeurIPS},
  selected={true},
  title={Benchmarking Structural Inference Methods for Interacting Dynamical Systems with Synthetic Data},
  author={Wang, Aoran and Tong, Tsz Pan and Mizera, Andrzej and Pang, Jun},
  booktitle={The Thirty-eight Conference on Neural Information Processing Systems Datasets and Benchmarks Track},
  year={2024},
  website={https://openreview.net/forum?id=kKtalvwqBZ},
  abstract={Understanding complex dynamical systems begins with identifying their topological structures, which expose the organization of the systems. This requires robust structural inference methods that can deduce structure from observed behavior. However, existing methods are often domain-specific and lack a standardized, objective comparison framework. We address this gap by benchmarking 13 structural inference methods from various disciplines on simulations representing two types of dynamics and 11 interaction graph models, supplemented by a biological experimental dataset to mirror real-world application. We evaluated the methods for accuracy, scalability, robustness, and sensitivity to graph properties. Our findings indicate that deep learning methods excel with multi-dimensional data, while classical statistics and information theory based approaches are notably accurate and robust. Additionally, performance correlates positively with the graph's average shortest path length. This benchmark should aid researchers in selecting suitable methods for their specific needs and stimulate further methodological innovation.}
}

@article{tong2024integrating,
  abbr={Arxiv},
  title={Integrating Optimal Transport and Structural Inference Models for GRN Inference from Single-cell Data},
  author={Tong, Tsz Pan and Wang, Aoran and Panagopoulos, George and Pang, Jun},
  journal={arXiv preprint arXiv:2409.15080},
  year={2024},
  pdf = {https://arxiv.org/pdf/2409.15080},
  abstract = {We introduce a novel gene regulatory network (GRN) inference method that integrates optimal transport (OT) with a deep-learning structural inference model. Advances in next-generation sequencing enable detailed yet destructive gene expression assays at the single-cell level, resulting in the loss of cell evolutionary trajectories. Due to technological and cost constraints, single-cell experiments often feature cells sampled at irregular and sparse time points with a small sample size. Although trajectory-based structural inference models can accurately reveal the underlying interaction graph from observed data, their efficacy depends on the inputs of thousands of regularly sampled trajectories. The irregularly-sampled nature of single-cell data precludes the direct use of these powerful models for reconstructing GRNs. Optimal transport, a classical mathematical framework that minimize transportation costs between distributions, has shown promise in multi-omics data integration and cell fate prediction. Utilizing OT, our method constructs mappings between consecutively sampled cells to form cell-level trajectories, which are given as input to a structural inference model that recovers the GRN from single-cell data. Through case studies in two synthetic datasets, we demonstrate the feasibility of our proposed method and its promising performance over eight state-of-the-art GRN inference methods.}
}


@inproceedings{wang-2024-sidec,
  abbr={ICLR},
  selected={true},
  title =    {Structural Inference with Dynamics Encoding and Partial Correlation Coefficients},
  author =       {Wang, Aoran and Pang, Jun},
  booktitle=    {The Twelfth International Conference on Learning Representations},
  year =   {2024},
  pdf =    {https://openreview.net/pdf?id=TKnzPdyeJu},
  website =    {https://openreview.net/pdf?id=TKnzPdyeJu},
  abstract =   {This paper introduces a novel approach to structural inference, combining a variational dynamics encoder with partial correlation coefficients. In contrast to prior methods, our approach leverages variational inference to encode node dynamics within latent variables, and structural reconstruction relies on the calculation of partial correlation coefficients derived from these latent variables. This unique design endows our method with scalability and extends its applicability to both one-dimensional and multi-dimensional feature spaces. Furthermore, by reorganizing latent variables according to temporal steps, our approach can effectively reconstruct directed graph structures. We validate our method through extensive experimentation on twenty datasets from a benchmark dataset and biological networks. Our results showcase the superior scalability, accuracy, and versatility of our proposed approach compared to existing methods. Moreover, experiments conducted on noisy data affirm the robustness of our method.}
}


@inproceedings{pmlr-v202-wang23ak,
  abbr={ICML},
  selected={true},
  title =    {Effective and Efficient Structural Inference with Reservoir Computing},
  author =       {Wang, Aoran and Tong, Tsz Pan and Pang, Jun},
  booktitle =    {Proceedings of the 40th International Conference on Machine Learning},
  pages =    {36391--36410},
  year =   {2023},
  volume =   {202},
  series =   {Proceedings of Machine Learning Research},
  publisher =    {PMLR},
  pdf =    {https://proceedings.mlr.press/v202/wang23ak/wang23ak.pdf},
  website =    {https://proceedings.mlr.press/v202/wang23ak.html},
  abstract =   {In this paper, we present an effective and efficient structural inference approach by integrating a Reservoir Computing (RC) network into a Variational Auto-encoder-based (VAE-based) structural inference framework. With the help of Bi-level Optimization, the backbone VAE-based method follows the Information Bottleneck principle and infers a general adjacency matrix in its latent space; the RC net substitutes the partial role of the decoder and encourages the whole approach to perform further steps of gradient descent based on limited available data. The experimental results on various datasets including biological networks, simulated fMRI data, and physical simulations show the effectiveness and efficiency of our proposed method for structural inference, either with much fewer trajectories or with much shorter trajectories compared with previous works.}
}


@inproceedings{pmlr-v202-wang23ac,
  abbr={ICML},
  selected={true},
  title =    {Active Learning based Structural Inference},
  author =       {Wang, Aoran and Pang, Jun},
  booktitle =    {Proceedings of the 40th International Conference on Machine Learning},
  pages =    {36224--36245},
  year =   {2023},
  volume =   {202},
  series =   {Proceedings of Machine Learning Research},
  publisher =    {PMLR},
  pdf =    {https://proceedings.mlr.press/v202/wang23ac/wang23ac.pdf},
  website =    {https://proceedings.mlr.press/v202/wang23ac.html},
  abstract =   {In this paper, we propose a novel framework, Active Learning based Structural Inference (ALaSI), to infer the existence of directed connections from observed agents’ states over a time period in a dynamical system. With the help of deep active learning, ALaSI is competent in learning the representation of connections with a relatively small pool of prior knowledge. Moreover, based on information theory, the proposed inter- and out-of-scope message learning pipelines are remarkably beneficial to structural inference for large dynamical systems. We evaluate ALaSI on various large datasets including simulated systems and real-world networks, to demonstrate that ALaSI is able to outperform previous methods in precisely inferring the existence of connections in large systems under either supervised learning or unsupervised learning.}
}

@inproceedings{aoran2022isidg,
  abbr={NeurIPS},
  selected={true},
  author = {Wang, Aoran and Pang, Jun},
  booktitle = {Advances in Neural Information Processing Systems},
  pages = {8717--8730},
  title = {Iterative Structural Inference of Directed Graphs},
  website={https://papers.nips.cc/paper_files/paper/2022/hash/39717429762da92201a750dd03386920-Abstract-Conference.html},
  pdf = {https://proceedings.neurips.cc/paper_files/paper/2022/file/39717429762da92201a750dd03386920-Paper-Conference.pdf},
  volume = {35},
  year = {2022},
  abstract =   {In this paper, we propose a variational model, iterative Structural Inference of Directed Graphs (iSIDG), to infer the existence of directed interactions from observational agents’ features over a time period in a dynamical system. First, the iterative process in our model feeds the learned interactions back to encourage our model to eliminate indirect interactions and to emphasize directional representation during learning. Second, we show that extra regularization terms in the objective function for smoothness, connectiveness, and sparsity prompt our model to infer a more realistic structure and to further eliminate indirect interactions. We evaluate iSIDG on various datasets including biological networks, simulated fMRI data, and physical simulations to demonstrate that our model is able to precisely infer the existence of interactions, and is significantly superior to baseline models.}
}

@inproceedings{9294630,
  abbr={ITSC},
  author={Hu, Haohao and Wang, Aoran and Sons, Marc and Lauer, Martin},
  booktitle={2020 IEEE 23rd International Conference on Intelligent Transportation Systems (ITSC)}, 
  title={ViPNet: An End-to-End 6D Visual Camera Pose Regression Network}, 
  year={2020},
  volume={},
  number={},
  pages={1-7},
  doi={10.1109/ITSC45102.2020.9294630},
  abstract={In this work, we present a visual pose regression network: ViPNet. It is robust and real-time capable on mobile platforms such as self-driving vehicles. We train a convolutional neural network to estimate the six degrees of freedom camera pose from a single monocular image in an end-to-end manner. In order to estimate camera poses with uncertainty, we use a Bayesian version of the ResNet-50 as our basic network. SEBlocks are applied in residual units to increase our model's sensitivity to informative features. Our ViPNet is trained using a geometric loss function with trainable parameters, which can simplify the fine-tuning process significantly. We evaluate our ViPNet on the Cambridge Landmarks dataset and also on our Karl-Wilhelm-Plaza dataset, which is recorded with an experimental vehicle. As evaluation results, our ViPNet outperforms other end-to-end monocular camera pose estimation methods. Our ViPNet requires only 9-15ms to predict one camera pose, which allows us to run it with a very high frequency.}
}
